{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN is devloped for sequential data . it is also a neural network\n",
    "#Sequential data---> it is text data and time series data .because the sequence of text is important if we split the text to each other then the meaning of text not still same \n",
    "# time seiries data--> based on the time it take prediction \n",
    "# activation function on hidden layer in rnn is   [ tanh ] and return the value between -1 to +1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the type of message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=open(\"./Data/train.txt\").readlines()\n",
    "test_data=open(\"./Data/test.txt\").readlines()\n",
    "validation_data=open(\"./Data/val.txt\").readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(validation_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data=[]\n",
    "for i in train_data:\n",
    "    complete_data.append(train_data)\n",
    "for j in test_data:\n",
    "    complete_data.append(test_data)\n",
    "for v in validation_data:\n",
    "    complete_data.append(validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_data2=train_data+test_data+validation_data\n",
    "# print(len(complete_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "# for message in complete_data:\n",
    "#     for j in range(len(message)):\n",
    "#         if message[j]==\";\":\n",
    "#             x.append(message[0:j])\n",
    "#             y.append(i[j+1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for temp in complete_data:\n",
    "    if isinstance(temp, str):  # Check if temp is a string\n",
    "        complete = temp.split(';')\n",
    "        if len(complete) == 2:\n",
    "            x.append(complete[0])\n",
    "            y.append(complete[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=[]\n",
    "# y=[]\n",
    "# for temp in complete_data:\n",
    "#     complete = temp.split(';')\n",
    "#     if len(complete)==2:\n",
    "#         x.append(complete[0])\n",
    "#         y.append(complete[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_label=set(y)\n",
    "unique_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without set function\n",
    "\n",
    "labels=[]\n",
    "for item in y:\n",
    "        if item not in labels:\n",
    "            labels.append(item)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "# convert all message in lower case\n",
    "# a-z, 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(sentences):\n",
    "    for sentence in sentences:\n",
    "        message=sentence.lower()\n",
    "        message=re.sub('[^a-z0-9 ]',\"\",message)\n",
    "        ls_of_words=nltk.word_tokenize(message)\n",
    "        \n",
    "clean_data=text_cleaning(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m single_message\u001b[38;5;241m=\u001b[39m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      2\u001b[0m single_message\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-z0-9 ]\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,single_message)\n\u001b[0;32m      3\u001b[0m single_message\u001b[38;5;241m.\u001b[39msplit()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "single_message=x[1].lower()\n",
    "single_message=re.sub('[^a-z0-9 ]',\"\",single_message)\n",
    "ls_of_words= nltk.word_tokenize(single_message)    # single_message.split()\n",
    "\n",
    "# Tokenization (message is divide by the seprate words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words remove\n",
    "# stemming or lemmaltizations\n",
    "# RNN or LSTM (advanced version of rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
